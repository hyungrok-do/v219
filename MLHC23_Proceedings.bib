@Proceedings{MLHC-2023,
    booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
    editor = {Kaivalya Deshpande and Madalina Fiterau and Shalmali Joshi and   Zachary Lipton and Rajesh Ranganath and  I\~nigo Urteaga and Serene Yeung},
    volume = {219},
    shortname = {MLHC},
    name = {Machine Learning for Healthcare Conference},
    year = {2023},
    start = {2023-08-11},
    end = {2023-08-12},
    published = {2023-12-22},
    url = {http://mlforhc.org/},
    address = {New York, USA},
    conference_number = {8},
    shortname = {MLHC}
}

@inproceedings{Adams23,
	Abstract = {Long-form clinical summarization of hospital admissions has real-world significance because of its potential to help both clinicians and patients. The factual consistency of summaries– their faithfulness–is critical to their safe usage in clinical settings. To better understand the limitations of state-of-the-art natural language processing (NLP) systems, as well as the suitability of existing evaluation metrics, we benchmark faithfulness metrics against fine-grained human annotations for model-generated summaries of a patient’s Brief Hospi tal Course. We create a corpus of patient hospital admissions and summaries for a cohort of HIV patients, each with complex medical histories. Annotators are presented with summaries and source notes, and asked to categorize manually highlighted summary elements (clinical entities like conditions and medications as well as actions like ”following up”) into one of three categories: “Incorrect,” “Missing,” and “Not in Notes.” We meta-evaluate a broad set of faithfulness metrics–proposed for the general NLP domain–by measuring the correlation of metric scores to clinician ratings. Across metrics, we explore the importance of domain adaptation (e.g. the impact of in-domain pre-training and metric fine-tuning), the use of source-summary alignments, and the effects of distilling a single metric from an ensemble. We find that off-the-shelf metrics with no exposure to clinical text correlate well to clinician ratings yet overly rely on copy-and-pasted text. As a practical guide, we observe that most metrics correlate best to clinicians when provided with one summary sentence at a time and a minimal set of supporting sentences from the notes before discharge.},
	Author = {Griffin Adams and Jason Zuckerg and N\'oemie Elhadad},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {2-30},
	Title = {A Meta-Evaluation of Faithfulness Metrics for Long-Form Hospital-Course Summarization},
	Volume = {219},
	Year = {2023}}

@inproceedings{Ayad23,
	Abstract = {Cervical cancer is a life-threatening disease and one of the most prevalent types of cancer affecting women worldwide. Being able to adequately identify and assess factors that elevate risk of cervical cancer is crucial for early detection and treatment. Advances in machine learning have produced new methods for predicting cervical cancer risk, however their complex black-box behaviour remains a key barrier to their adoption in clinical practice. Recently, there has been substantial rise in the development of local explainability techniques aimed at breaking down a model’s predictions for particular instances in terms of, for example, meaningful concepts, important features, decision tree or rule-based logic, among others. While these techniques can help users better understand key factors driving a model’s decisions in some situations, they may not always be consistent or provide faithful predictions, particularly in applications with heterogeneous outcomes. In this paper, we present a critical analysis of several existing local interpretability methods for explaining risk factors associated with cervical cancer. Our goal is to help clinicians who use AI to better understand which types of explanations to use in particular contexts. We present a framework for studying the quality of different explanations for cervical cancer risk and contextualise how different explanations might be appropriate for different patient scenarios through an empirical analysis. Finally, we provide practical advice for practitioners as to how to use different types of explanations for assessing and determining key factors driving cervical cancer risk.},
	Author = {Celia Wafa Ayad and Thomas Bonnier and Benjamin Bosch and Jesse Read and Sonali Parbhoo},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {31-49},
	Title = {Which Explanation Makes Sense? A Critical Evaluation of Local Explanations for Assessing Cervical Cancer Risk},
	Volume = {219},
	Year = {2023}}

@inproceedings{Behrouz23,
	Abstract = {The human brain is at the center of complex neurobiological systems, and understanding its structural and functional mechanisms remains an intriguing goal for neuroscience research. While magnetic resonance imaging (MRI) is one of the most widespread and important sources of neurological data, it poses daunting analysis challenges. Due to recent advances in graph theory and machine learning on graphs, representing the connections of the human brain as a network has become one of the most pervasive analytical paradigms. However, most existing graph machine learning-based methods suffer from a subset of four critical limitations: They are 1) designed for one type of data (e.g., fMRI or sMRI) and one individual subject, limiting their ability to use complementary information provided by different images. 2) designed in supervised or transductive settings, limiting their generalizability to unseen patterns. 3) designed for classifying brain networks, limiting their ability to reveal underlying patterns that might cause the symptoms of a disease or disorder. 4) frequently unable to scale to large numbers of samples. To address the first limitation, we suggest using multiplex networks–networks with different types of connections– to model the network of different data samples. We present ADMire, an inductive and unsupervised anomaly detection method for multiplex brain networks that can detect anomalous patterns in the brains of people living with a disease or disorder. It uses two different casual multiplex walks, inter-view and intra-view, to automatically extract and learn temporal network motifs. It then uses an anonymization strategy to hide node identity, keeping the model inductive. We then propose a novel negative sample generator strategy for multiplex networks that lets our model learn anomalous patterns in an unsupervised manner. Our experiments on Parkinson’s Disease, Attention Deficit Hyperactivity Disorder, and Autism Spectrum Disorder show the efficiency and effectiveness of our approach in detecting anomalous brain activity in people living with these diseases or disorders.},
	Author = {Ali Behrouz and Margo Seltzer},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {50-75},
	Title = {Anomaly Detection in Human Brain via Inductive Learning on Temporal Multiplex Networks},
	Volume = {219},
	Year = {2023}}

@inproceedings{Calhas23,
	Abstract = {Topographical structures represent connections between entities and provide a comprehensive design of complex systems. Currently these structures are used to discover correlates of neuronal and haemodynamical activity. In this work, we incorporate them with neural processing techniques to perform regression, using electrophysiological activity to retrieve haemodynamics. To this end, we use Fourier features, attention mechanisms, shared space between modalities and incorporation of style in the latent representation. By combining these techniques, we propose several models that significantly outperform current state-of-the-art of this task in resting state and task-based recording settings. Additionally, we show how the developed mapping functions are able to extrapolate to a diagnostic setting. We report which EEG electrodes are the most relevant for the regression task and which relations impacted it the most. Complementary, we observe that haemodynamic activity at the scalp, in contrast with sub-cortical regions, is relevant to the learned shared space. Overall, these results suggest that EEG electrode relationships are pivotal to retain information necessary for haemodynamical activity retrieval.},
	Author = {David Calhas and Rui Henriques},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {76-93},
	Title = {EEG to fMRI Synthesis Benefits from Attentional Graphs of Electrode Relationships},
	Volume = {219},
	Year = {2023}}

@inproceedings{Cheng23,
	Abstract = {Reliable extraction of temporal relations from clinical notes is a growing need in many clinical research domains. Our work introduces typed markers to the task of clinical temporal relation extraction. We demonstrate that the addition of medical entity information to clinical text as tags with context sentences then input to a transformer-based architecture can outperform more complex systems requiring feature engineering and temporal reasoning. We propose several strategies of typed marker creation that incorporate entity type information at different granularities, with extensive experiments to test their effectiveness. Our system establishes the best result on I2B2, a clinical benchmark dataset for temporal relation extraction, with a F1 at 83.5% that provides a substantial 3.3% improvement over the previous best system.},
	Author = {Cheng Cheng and Jeremy C. Weiss},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {94-109},
	Title = {Typed Markers and Context for Clinical Temporal Relation Extraction},
	Volume = {219},
	Year = {2023}}

@inproceedings{Compton23,
	Abstract = {In machine learning, incorporating more data is often seen as a reliable strategy for improving model performance; this work challenges that notion by demonstrating that the addition of external datasets in many cases can hurt the resulting model’s performance. In a large-scale empirical study across combinations of four different open-source chest x-ray datasets and 9 different labels, we demonstrate that in 43\% of settings, a model trained on data from two hospitals has poorer worst group accuracy over both hospitals than a model trained on just a single hospital’s data. This surprising result occurs even though the added hospital makes the training distribution more similar to the test distribution. We explain that this phenomenon arises from the spurious correlation that emerges between the disease and hospital, due to hospital-specific image artifacts. We highlight the trade-off one encounters when training on multiple datasets, between the obvious benefit of additional data and insidious cost of the introduced spurious correlation. In some cases, balancing the dataset can remove the spurious correlation and improve performance, but it is not always an effective strategy. We contextualize our results within the literature on spurious correlations to help explain these outcomes. Our experiments underscore the importance of exercising caution when selecting training data for machine learning models, especially in settings where there is a risk of spurious correlations such as with medical imaging. The risks outlined highlight the need for careful data selection and model evaluation in future research and practice.},
	Author = {Rhys Compton and Lily Zhang and Aahlad Puli and Rajesh Ranganath},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {110-127},
	Title = {When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations},
	Volume = {219},
	Year = {2023}}

@inproceedings{Do23,
	Abstract = {Survival analysis is a general framework for predicting the time until a specific event occurs, often in the presence of censoring. Although this framework is widely used in practice, few studies to date have considered fairness for time-to-event outcomes, despite recent significant advances in the algorithmic fairness literature more broadly. In this paper, we propose a framework to achieve demographic parity in survival analysis models by minimizing the mutual information between predicted time-to-event and sensitive attributes. We show that our approach effectively minimizes mutual information to encourage statistical independence of time-to-event predictions and sensitive attributes. Furthermore, we propose four types of disparity assessment metrics based on common survival analysis metrics. Through experiments on multiple benchmark datasets, we demonstrate that by minimizing the dependence between the prediction and the sensitive attributes, our method can systematically improve the fairness of survival predictions and is robust to censoring.},
	Author = {Hyungrok Do and Yuxin Chang and Yoon Sang Cho and Padhraic Smyth and Judy Zhong},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {128-149},
	Title = {When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations},
	Volume = {219},
	Year = {2023}}

@inproceedings{Elhussein23,
	Abstract = {Federated Learning (FL) is a machine learning framework that enables multiple organizations to train a model without sharing their data with a central server. However, it experiences significant performance degradation if the data is non-identically independently distributed (non-IID). This is a problem in medical settings, where variations in the patient population contribute significantly to distribution differences across hospitals. Personalized FL addresses this issue by accounting for site-specific distribution differences. Clustered FL, a Personalized FL variant, was used to address this problem by clustering patients into groups across hospitals and training separate models on each group. However, privacy concerns remained as a challenge as the clustering process requires exchange of patient-level information. This was previously solved by forming clusters using aggregated data, which led to inaccurate groups and performance degradation. In this study, we propose Privacy-preserving Community-Based Federated machine Learning (PCBFL), a novel Clustered FL framework that can cluster patients using patient-level data while protecting privacy. PCBFL uses Secure Multiparty Computation, a cryptographic technique, to securely calculate patient-level similarity scores across hospitals. We then evaluate PCBFL by training a federated mortality prediction model using 20 sites from the eICU dataset. We compare the performance gain from PCBFL against traditional and existing Clustered FL frameworks. Our results show that PCBFL successfully forms clinically meaningful cohorts of low, medium, and high-risk patients. PCBFL outperforms traditional and existing Clustered FL frameworks with an average AUC improvement of 4.3% and AUPRC improvement of 7.8%.},
	Author = {Ahmed Elhussein and Gamze G\"ursoy},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {150-166},
	Title = {Privacy-preserving patient clustering for personalized federated learnings},
	Volume = {219},
	Year = {2023}}

@inproceedings{Fayyaz23,
	Abstract = {Sleep apnea in children is a major health problem affecting one to five percent of children (in the US). If not treated in a timely manner, it can also lead to other physical and mental health issues. Pediatric sleep apnea has different clinical causes and characteristics than adults. Despite a large group of studies dedicated to studying adult apnea, pediatric sleep apnea has been studied in a much less limited fashion. Relatedly, at-home sleep apnea testing tools and algorithmic methods for automatic detection of sleep apnea are widely present for adults, but not children. In this study, we target this gap by presenting a machine learning-based model for detecting apnea events from commonly collected sleep signals. We show that our method outperforms state-of-the-art methods across two public datasets, as determined by the F1-score and AUROC measures. Additionally, we show that using two of the signals that are easier to collect at home (ECG and SpO2) can also achieve very competitive results, potentially addressing the concerns about collecting various sleep signals from children outside the clinic. Therefore, our study can greatly inform ongoing progress toward increasing the accessibility of pediatric sleep apnea testing and improving the timeliness of the treatment interventions.},
	Author = {Hamed Fayyaz and Abigail Strang and Rahmatollah Beheshti},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {167-185},
	Title = {Bringing At-home Pediatric Sleep Apnea Testing Closer to Reality: A Multi-modal Transformer Approach},
	Volume = {219},
	Year = {2023}}

@inproceedings{Ferdous23,
	Abstract = {Time series data are found in many areas of healthcare such as medical time series, electronic health records (EHR), measurements of vitals, and wearable devices. Causal discovery, which involves estimating causal relationships from observational data, holds the potential to play a significant role in extracting actionable insights about human health. In this study, we present a novel constraint-based causal discovery approach for autocorrelated and non-stationary time series data (CDANs). Our proposed method addresses several limitations of existing causal discovery methods for autocorrelated and non-stationary time series data, such as high dimensionality, the inability to identify lagged causal relationships and overlooking changing modules. Our approach identifies lagged and instantaneous/contemporaneous causal relationships along with changing modules that vary over time. The method optimizes the conditioning sets in a constraint-based search by considering lagged parents instead of conditioning on the entire past that addresses high dimensionality. The changing modules are detected by considering both contemporaneous and lagged parents. The approach first detects the lagged adjacencies, then identifies the changing modules and contemporaneous adjacencies, and finally determines the causal direction. We extensively evaluated our proposed method on synthetic and real-world clinical datasets, and compared its performance with several baseline approaches. The experimental results demonstrate the effectiveness of the proposed method in detecting causal relationships and changing modules for autocorrelated and non-stationary time series data.},
	Author = {Muhammad Hasan Ferdous and  Uzma Hasan and Md Osman Gani},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {186-207},
	Title = {CDANs: Temporal Causal Discovery from Autocorrelated and Non-Stationary Time Series Data},
	Volume = {219},
	Year = {2023}}

@inproceedings{Fresacher23,
	Abstract = {Thrombotic complications are a leading cause of death worldwide, often triggered by inflammatory conditions such as sepsis and COVID-19, due to a close relationship between inflammation and hemostasis known as immunothrombosis. Platelet activation and leukocyte-platelet aggregation play key roles in microthrombotic events, yet there are no routine diagnostic predictive biomarkers based on these factors. This work presents a novel processing pipeline using label-free Quantitative Phase Imaging (QPI) for the detection and quantitative analysis of blood cell aggregates without sample preparation. For evaluation, we use different test scenarios and measure performance at different stages of the pipeline to gain a better understanding of the critical points. We show that, among other classical and machine learning techniques, the Mask R-CNN approach achieves the best results for detection, segmentation, and classification of cell aggregates. The method successfully identifies aggregate levels in whole blood samples and shows elevated levels in >90% of patients with COVID-19 or sepsis compared to healthy reference samples, indicating the potential of platelet and leukocyte-platelet aggregates as biomarkers for thrombotic diseases.},
	Author = {David Fresacher and Stefan R\"ohrl and  Christian Klenk and  Johanna Erber and  Hedwig Irl and  Dominik Heim and  Manuel Lengl and Simon Schumann and Martin Knopp and Martin Schlegel and  Sebastian Rasch and  Oliver Hayden and Klaus Diepold},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {208-229},
	Title = {Composition Counts: A Machine Learning View on Immunothrombosis using Quantitative Phase Imaging},
	Volume = {219},
	Year = {2023}}

@inproceedings{Gulamali23,
	Abstract = {Univariate high-frequency time series are dominant data sources for many medical, economic and environmental applications. In many of these domains, the time series are tied to real-time changes in state. In the intensive care unit, for example, changes and intracranial pressure waveforms can indicate whether a patient is developing decreased blood perfusion to the brain during a stroke, for example. However, most representation learning to resolve states is conducted in an offline, batch-dependent manner. In high frequency time-series, high intra-state and inter-sample variability makes offline, batch-dependent learning a relatively difficult task. Hence, we propose Spatial Resolved Temporal Networks (SpaRTeN), a novel composite deep learning model for online, unsupervised representation learning through a spatially constrained latent space. SpaRTeN maps waveforms to states, and learns time-dependent representations of each state. Our key contribution is that we generate clinically relevant representations of each state for intracranial pressure waveforms.},
	Author = {Faris Gulamali and  Ashwin Sawant and Ira Hofer and Matthew Levin and Alexander Charney and Karandeep Singh and Benjamin Glicksberg and Girish Nadkarni},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {230-247},
	Title = {Online Unsupervised Representation Learning of Waveforms in the Intensive Care Unit via a novel cooperative framework: Spatially Resolved Temporal Networks (SpaRTEn)},
	Volume = {219},
	Year = {2023}}

@inproceedings{He23,
	Abstract = {With the increasing popularity of telehealth, it is crucial to ensure accurate monitoring of basic physiological signals at home with minimal patient overhead. In this paper, we propose a contactless approach for monitoring blood oxygen levels simply by analyzing radio signals in a patient’s room, without the need for wearable devices. Our method extracts a patient’s respiration from radio signals that bounce off their body, and we use a novel neural network, called Gated BERT-UNet, to estimate blood oxygen saturation from the breathing signal. We designed our model to adapt to a patient’s medical indices, such as gender and sleep stages, to provide personalized inference. Specifically, it uses multiple predictive heads, controlled by a gate, to make predictions for different sub-populations. Our extensive empirical results demonstrate that our model achieves high accuracy on both medical and radio-frequency datasets. It outperforms past work on contactless oxygen monitoring, reducing the mean absolute error in oxygen saturation from 2.0% to 1.3%.},
	Author = {Hao He and Yuan Yuan and Ying-Cong Chen and Peng Cao and Dina Katabi},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {248-265},
	Title = {Contactless Oxygen Monitoring with Radio Waves and Gated Transformer},
	Volume = {219},
	Year = {2023}}

@inproceedings{Ho23,
	Abstract = {Colorectal cancer (CRC) is a leading cause of cancer-related deaths worldwide, with a high incidence of recurrence following surgical resection. Accurate prognostication of recurrence risk is essential to identify patients who may benefit from adjuvant therapies and improve their health outcomes. In our study, we propose a novel approach to CRC recurrence prognostication using multi-view deep learning. Our proposed approach, Fusion with Multi-view Attention (FMA), integrates static and longitudinal data from heterogeneous healthcare records, and learns complex interactions between data views to predict recurrence and time-to-recurrence. Our model achieves an AUROC score of 0.97, and precision, sensitivity and specificity scores of 0.80, 0.90 and 0.95 respectively, outperforming all-known published results based on the commonly-used CEA prognostic marker, as well as state-of-the-art CRC recurrence prognostication models. We show through a sensitivity analysis that incorporating multiple data views improves model performance significantly compared to using only a single view. We also show that our model accurately stratifies patients into risk groups that are associated with the actual 5-year recurrence-free survival, paving the way towards better identification of high-risk patients who may benefit from adjuvant therapies. Our proposed approach demonstrates the potential of multi-view modelling to push state-of-the-art in CRC recurrence prognostication and could contribute towards more personalised patient management and follow-up in the clinic.},
	Author = {Danliang Ho and Mehul Motani},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {265-284},
	Title = {Multi-view Modelling of Longitudinal Health Data for Improved Prognostication of Colorectal Cancer Recurrence},
	Volume = {219},
	Year = {2023}}
	
@inproceedings{Huang23,
	Abstract = {Aortic stenosis (AS) is a degenerative valve condition that causes substantial morbidity and mortality. This condition is under-diagnosed and under-treated. In clinical practice, AS is diagnosed with expert review of transthoracic echocardiography, which produces dozens of ultrasound images of the heart. Only some of these views show the aortic valve. To automate screening for AS, deep networks must learn to mimic a human expert’s ability to identify views of the aortic valve then aggregate across these relevant images to produce a study-level diagnosis. We find previous approaches to AS detection yield insufficient accuracy due to relying on inflexible averages across images. We further find that off-the-shelf attention-based multiple instance learning (MIL) performs poorly. We contribute a new end-to-end MIL approach with two key methodological innovations. First, a supervised attention technique guides the learned attention mechanism to favor relevant views. Second, a novel self-supervised pretraining strategy applies contrastive learning on the representation of the whole study instead of individual images as commonly done in prior literature. Experiments on an open-access dataset and a temporally-external heldout set show that our approach yields higher accuracy while reducing model size.},
	Author = {Zhe Huang and Benjamin S. Wessler and Michael C. Hughes},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {285-307},
	Title = {Detecting Heart Disease from Multi-View Ultrasound Images via Supervised Attention Multiple Instance Learning},
	Volume = {219},
	Year = {2023}}
	
@inproceedings{Isik23,
	Abstract = {Recently proposed encoder-decoder structures for modeling Hawkes processes use transformer-inspired architectures, which encode the history of events via embeddings and self-attention mechanisms. These models deliver better prediction and goodness-of-fit than their RNN-based counterparts. However, they often require high computational and memory complexity and fail to adequately capture the triggering function of the underlying process. So motivated, we introduce an efficient and general encoding of the historical event sequence by replacing the complex (multilayered) attention structures with triggering kernels of the observed data. Noting the similarity between the triggering kernels of a point process and the attention scores, we use a triggering kernel to replace the weights used to build history representations. Our estimator for the triggering function is equipped with a sigmoid gating mechanism that captures local-in-time triggering effects that are otherwise challenging with standard decaying-over-time kernels. Further, taking both event type representations and temporal embeddings as inputs, the model learns the underlying triggering type-time kernel parameters given pairs of event types. We present experiments on synthetic and real data sets widely used by competing models, and further include a COVID-19 dataset to illustrate the use of longitudinal covariates. Our results show the proposed model outperforms existing approaches, is more efficient in terms of computational complexity, and yields interpretable results via direct application of the newly introduced kernel.},
	Author = {Yamac Isik and  Paidamoyo Chapfuwa and Connor Davis and  Ricardo Henao},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {308-320},
	Title = {Hawkes Process with Flexible Triggering Kernels},
	Volume = {219},
	Year = {2023}}
	
@inproceedings{Jeong23,
	Abstract = {Heart failure is a debilitating condition that affects millions of people worldwide and has a significant impact on their quality of life and mortality rates. An objective assessment of cardiac pressures remains an important method for the diagnosis and treatment prognostication for patients with heart failure. Although cardiac catheterization is the gold standard for estimating central hemodynamic pressures, it is an invasive procedure that carries inherent risks, making it a potentially dangerous procedure for some patients. Approaches that leverage non-invasive signals – such as the electrocardiogram (ECG) – have the promise to make the routine estimation of cardiac pressures feasible in both inpatient and outpatient settings. Prior models trained to estimate intracardiac pressures (e.g., mean pulmonary capillary wedge pressure (mPCWP)) in a supervised fashion have shown good discriminatory ability but have been limited to the labeled dataset from the heart failure cohort. Furthermore, obtaining large datasets for diverse patient cohorts with intracardiac pressure labels is challenging due to the invasive nature of the procedure. To address these issues and build a robust representation, we apply traditional deep metric learning (DML) and propose a novel self-supervised DML with distance-based mining that improves the performance of a model with limited labels. We use a dataset that contains over 5.4 million ECGs without concomitant central pressure labels to pre-train a self-supervised DML model which showed improved classification of elevated mPCWP compared to self-supervised contrastive baselines. Additionally, the supervised DML model that uses ECGs with access to 8,172 mPCWP labels demonstrated significantly better performance on the mPCWP regression task compared to the supervised baseline. Moreover, our data suggest that DML yields models that are performant across patient subgroups, even when some patient subgroups are under-represented in the dataset.},
	Author = {Hyewon Jeong and Collin M. Stultz and Marzyeh Ghassemi},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {321-342},
	Title = {Deep Metric Learning for the Hemodynamics Inference with Electrocardiogram Signals},
	Volume = {219},
	Year = {2023}}

@inproceedings{Jiang23,
	Abstract = {The large amount of time clinicians spend sifting through patient notes and documenting in electronic health records (EHRs) is a leading cause of clinician burnout. By proactively and dynamically retrieving relevant notes during the documentation process, we can reduce the effort required to find relevant patient history. In this work, we conceptualize the use of EHR audit logs for machine learning as a source of supervision of note relevance in a specific clinical context, at a particular point in time. Our evaluation focuses on the dynamic retrieval in the emergency department, a high acuity setting with unique patterns of information retrieval and note writing. We show that our methods can achieve an AUC of 0.963 for predicting which notes will be read in an individual note writing session. We additionally conduct a user study with several clinicians and find that our framework can help clinicians retrieve relevant information more efficiently. Demonstrating that our framework and methods can perform well in this demanding setting is a promising proof of concept that they will translate to other clinical settings and data modalities (e.g., labs, medications, imaging).},
	Author = {Sharon Jiang and Shannon Shen and  Monica Agrawal and Barbara Lam and Nicholas Kurtzman and Steven Horng and David R. Karger and  David Sontag},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {343-359},
	Title = {Conceptualizing Machine Learning for Dynamic Information Retrieval of Electronic Health Record Notes},
	Volume = {219},
	Year = {2023}}
	
@inproceedings{Ketenci23,
	Abstract = {Survival analysis is a widely-used technique for analyzing time-to-event data in the presence of censoring. In recent years, numerous survival analysis methods have emerged which scale to large datasets and relax traditional assumptions such as proportional hazards. These models, while being performant, are very sensitive to model hyperparameters including: (1) number of bins and bin size for discrete models and (2) number of cluster assignments for mixture-based models. Each of these choices requires extensive tuning by practitioners to achieve optimal performance. In addition, we demonstrate in empirical studies that: (1) optimal bin size may drastically differ based on the metric of interest (e.g., concordance vs brier score), and (2) mixture models may suffer from mode collapse and numerical instability. We propose a survival analysis approach which eliminates the need to tune hyperparameters such as mixture assignments and bin sizes, reducing the burden on practitioners. We show that the proposed approach matches or outperforms baselines on several real-world datasets.},
	Author = {Mert Ketenci and  Shreyas Bhave and  Noemie Elhadad and  Adler Perotte},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {360-380},
	Title = {Maximum Likelihood Estimation of Flexible Survival Densities with Importance Sampling},
	Volume = {219},
	Year = {2023}}
	
@inproceedings{Khanna23,
	Abstract = {We present RadGraph2, a novel dataset for extracting information from radiology reports that focuses on capturing changes in disease state and device placement over time. We introduce a hierarchical schema that organizes entities based on their relationships and show that using this hierarchy during training improves the performance of an information extraction model. Specifically, we propose a modification to the DyGIE++ framework, resulting in our model HGIE, which outperforms previous models in entity and relation extraction tasks. We demonstrate that RadGraph2 enables models to capture a wider variety of findings and perform better at relation extraction compared to those trained on the original RadGraph dataset. Our work provides the foundation for developing automated systems that can track disease progression over time and develop information extraction models that leverage the natural hierarchy of labels in the medical domain.},
	Author = {Sameer Khanna and Adam Dejl and Kibo Yoon and Steven QH Truong  and Hanh Duong and Agustina Saenz and Pranav Rajpurkar},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {381-402},
	Title = {RadGraph2: Modeling Disease Progression in Radiology Reports via Hierarchical Information Extraction},
	Volume = {219},
	Year = {2023}}
	
@inproceedings{Labach23,
	Abstract = {Electronic health records (EHRs) recorded in hospital settings typically contain a wide range of numeric time series data that is characterized by high sparsity and irregular observations. Effective modelling for such data must exploit its time series nature, the semantic relationship between different types of observations, and information in the sparsity structure of the data. Self-supervised Transformers have shown outstanding performance in a variety of structured tasks in NLP and computer vision. But multivariate time series data contains structured relationships over two dimensions: time and recorded event type, and straightforward applications of Transformers to time series data do not leverage this distinct structure. The quadratic scaling of self-attention layers can also significantly limit the input sequence length without appropriate input engineering. We introduce the DuETT architecture, an extension of Transformers designed to attend over both time and event type dimensions, yielding robust representations from EHR data. DuETT uses an aggregated input where sparse time series are transformed into a regular sequence with fixed length; this lowers the computational complexity relative to previous EHR Transformer models and, more importantly, enables the use of larger and deeper neural networks. When trained with self-supervised prediction tasks, that provide rich and informative signals for model pre-training, our model outperforms state-of-the-art deep learning models on multiple downstream tasks from the MIMIC-IV and PhysioNet-2012 EHR datasets.},
	Author = {Alex Labach and Aslesha Pokhrel and Xiao Shi Huang and Saba Zuberi and Seung Eun Yi and Maksims Volkovs and Tomi Poutanen and Rahul G. Krishnan},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {403-422},
	Title = {DuETT: Dual Event Time Transformer for Electronic Health Records},
	Volume = {219},
	Year = {2023}}
	
@inproceedings{Lee23,
	Abstract = {Electronic Health Record (EHR) provides abundant information through various modalities. However, learning multi-modal EHR is currently facing two major challenges, namely, 1) irregular and asynchronous sampling and 2) modality missing. Moreover, a lack of shared embedding function across modalities can discard the temporal relationship between different EHR modalities. On the other hand, most EHR studies are limited to relying only on EHR Times-series, and therefore, missing modality in EHR has not been well-explored. Therefore, in this study, we introduce a Unified Multi-modal Set Embedding (UMSE) and Modality-Aware Attention (MAA) with Skip Bottleneck (SB). UMSE treats all EHR modalities without a separate imputation module or error-prone carry-forward, whereas MAA with SB learns missing modal EHR with effective modality-aware attention. Our model outperforms other baseline models in mortality, vasopressor need, and intubation need prediction with the MIMIC-IV dataset.},
	Author = {Kwanhyung Lee and Soojeong Lee and  Sangchul Hahn and Heejung Hyun and Edward Choi and  Byungeun Ahn and Joohyung Lee},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {423-442},
	Title = {Learning Missing Modal Electronic Health Records with Unified Multi-modal Data Embedding and Modality-Aware Attention},
	Volume = {219},
	Year = {2023}}
	
@inproceedings{Movva23,
	Abstract = {Healthcare data in the United States often records only a patient’s coarse race group: for example, both Indian and Chinese patients are typically coded as “Asian.” It is unknown, however, whether this coarse coding conceals meaningful disparities in the performance of clinical risk scores across granular race groups. Here we show that it does. Using data from 418K emergency department visits, we assess clinical risk score performance disparities across 26 granular groups for three outcomes, five risk scores, and four performance metrics. Across outcomes and metrics, we show that the risk scores exhibit significant granular performance disparities within coarse race groups. In fact, variation in performance within coarse groups often exceeds the variation between coarse groups. We explore why these disparities arise, finding that outcome rates, feature distributions, and relationships between features and outcomes all vary significantly across granular groups. Our results suggest that healthcare providers, hospital systems, and machine learning researchers should strive to collect, release, and use granular race data in place of coarse race data, and that existing analyses may significantly underestimate racial disparities in performance.},
	Author = {Rajiv Movva and Divya Shanmugam and  Kaihua Hou and Priya Pathak and  John Guttag and  Nikhil Garg and Emma Pierson},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {443-472},
	Title = {Coarse race data conceals disparities in clinical risk score performance},
	Volume = {219},
	Year = {2023}}
	
@inproceedings{Nakashima23,
	Abstract = {Applying deep learning to medical imaging tasks is not straightforward due to the variable quality and relatively low volume of healthcare data. There is often considerable risk that deep learning models may use contextual cues instead of physiologically relevant features to achieve the clinical task. Although these cues can provide shortcuts to high performance within a carefully crafted training set, they often lead to poor performance in real-world applications. Contrastive self-supervision (CSS) has recently been shown to boost performance of deep learning on downstream applications in several medical imaging tasks. However, it is unclear how much of these pre-trained representations are impacted by contextual cues, both known and unknown. In this work, we evaluate how CSS pre-training can produce not only more accurate but also more trustworthy and generalizable models for clinical imaging applications. Specifically, we evaluate the saliency and accuracy of deep learning models using CSS in contrast to end-to-end supervised training and conventional transfer learning from natural image datasets using an institutional specific and public cardiomyopathy cohorts. We find that CSS pre-training models not only improve downstream diagnostic performance in each cohort, but more importantly, also produced models with higher saliency in cardiac anatomy. Our code is available at https://github.com/makiya11/ssl_spur_cmr.},
	Author = {Makiya Nakashima and  Donna Salem and  HW Wilson Tang and Christopher Nguyen and Tae Hyun Hwang and Ding Zhao and  Byung-Hak Kim  and  Deborah Kwon  and  David Chen},	
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {473-488},
	Title = {Reducing Contextual Bias in Cardiac Magnetic Resonance Imaging Deep Learning Using Contrastive Self-Supervision},
	Volume = {219},
	Year = {2023}}
	
@inproceedings{Naseer23,
	Abstract = {Global access to statistically and clinically representative patient health data holds potential for advancing disease research, enhancing patient care, and accelerating drug development. However, acquisition of health data such as electronic health records (EHRs) comes with challenges characterised by high costs, time constraints, and concerns related to patient privacy. An approach to tackling these challenges is by using synthetic data. In this paper we introduce ScoEHR, a novel deep learning method for generating synthetic EHRs, which combines an autoencoder with a continuous-time diffusion model. ScoEHR is shown to outperform three baseline synthetic EHR generation frameworks (medGAN, medWGAN, and medBGAN) on two publicly available datasets, MIMIC-III and the Yale New Haven Health System Emergency Department dataset, based on four widely accepted metrics of data utility. Additionally, a blind clinician evaluation was carried out to assess the qualitative realism of the synthetic data generated by ScoEHR. In this evaluation, a patient’s data was labeled as ‘unrealistic’ if at least one clinician found it to be unrealistic. This evaluation showed that existing real EHR data and ScoEHR generated synthetic data were scored as equally realistic. Our code is available at https://github.com/aanaseer/ ScoEHR.},
	Author = {Ahmed Ammar Naseer and Benjamin Walker and Christopher Landon and  Andrew Ambrosy and  Marat Fudim and Nicholas Wysham and Botros Toro and Sumanth Swaminathan and  Terry Lyons},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {489-508},
	Title = {ScoEHR: Generating Synthetic Electronic Health Records using Continuous-time Diffusion Models},
	Volume = {219},
	Year = {2023}}
	
@inproceedings{Nolin-Lapalme23,
	Abstract = {The electrocardiogram (ECG) remains the cornerstone of diagnosis in cardiology where, pathologies uniquely impact its appearance, permitting the identification of underlying electrical or structural abnormalities. Notably, multiple deep learning approaches have demonstrated that disease prediction could be performed with high accuracy using ECG waveforms. However, this signal-rich modality has also demonstrated the potential to be predictive of a patient’s private attributes such as biological sex and age. More importantly, recent research has demonstrated that many medical data modalities could allow patient re-identification with only the modality of interest despite anonymization through current paradigms, raising important privacy concerns. In this paper, we propose a novel approach to anonymize the ECG waveforms themselves while maximizing the privacy-utility trade-off. We describe PrivECG1, a generative adversarial network (GAN) framework capable of privatizing 12-lead ECGs while conserving their disease-descriptive features. PrivECG significantly decreases patient validation performances by targeting sex-linked features. Our approach reduces sex prediction accuracy from 0.876 to near-random 0.529, by permitting greater variability of the ECG’s R-wave morphology, as well as bringing the equal error rate (EER) from 0.098 to 0.251 on individual validation tasks. Moreover, the regenerated ECGs maintain a majority of their disease-predicting potential, with an F1 score of 0.885 from the baseline’s 0.931 on a multilabel disease prediction task. We further demonstrate that reintroducing sex-linked information downstream in the network allows recuperating performances with an F1 score of 0.893 proving our loss of performance is due to the privatization of the sex-linked features, as well as serves as a disambiguation tool to evaluate the impact of sex information on prediction performances. Our results suggest that our approach could allow improved anonymization of a large ECG database in minutes without strongly impacting downstream clinically-relevant tasks in a task-independent manner.},
	Author = {Alexis Nolin-Lapalme and Robert Avram and Hussin Julie},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {509-528},
	Title = {PrivECG: generating private ECG for end-to-end anonymization},
	Volume = {219},
	Year = {2023}}

@inproceedings{Otles23,
	Abstract = {As data shift or new data become available, updating clinical machine learning models may be necessary to maintain or improve performance over time. However, updating a model can introduce compatibility issues when the behavior of the updated model does not align with user expectations, resulting in poor user-model team performance. Existing compatibility measures depend on model decision thresholds, limiting their applicability in settings where models are used to generate rankings based on estimated risk. To address this limitation, we propose a novel rank-based compatibility measure, CR, and a new loss function that aims to optimize discriminative performance while encouraging good compatibility. Applied to a case study in mortality risk stratification leveraging data from MIMIC, our approach yields more compatible models while maintaining discriminative performance compared to existing model selection techniques, with an increase in CR of 0.019 (95% confidence interval: 0.005, 0.035). This work provides new tools to analyze and update risk stratification models used in clinical care.},
	Author = {Erkin \"Otles and Brian T. Denton and Jenna Wiens},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {529-547},
	Title = {Updating Clinical Risk Stratification Models Using Rank-Based Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team Performance},
	Volume = {219},
	Year = {2023}}
	
@inproceedings{Palepu23,
	Abstract = {In this paper, we introduce a novel regularization scheme on contrastive language-image pre-trained (CLIP) medical vision models. Our approach is based on the observation that, for many medical imaging tasks, text tokens should only describe a small number of image regions and, likewise, each image region should correspond to only a few text tokens. In CLIP-style models, this implies that text-token embeddings should have high similarity to only a small number of image-patch embeddings for a given image-text pair. We formalize this observation using a novel regularization scheme that penalizes the entropy of the text-token to image-patch similarity scores. We qualitatively and quantitatively demonstrate that the proposed regularization scheme improves localization by shrinking most of the pairwise text-token and image-patch similarity scores towards zero, thus achieving the desired effect. We demonstrate the promise of our approach in an important medical context, chest x-rays, where this underlying sparsity hypothesis naturally arises. Using our proposed approach, we achieve state of the art (SOTA) average zero-shot performance on the CheXpert and Padchest chest x-ray datasets, outperforming an unregularized version of the model and several recently published self-supervised models.},
	Author = {Anil Palepu and Andrew Beam},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {548-564},
	Title = {TIER: Text-Image Entropy Regularization for Medical CLIP-style models},
	Volume = {219},
	Year = {2023}}
	
@inproceedings{Patel23,
	Abstract = {Manual segmentation of brain metastases (BM) is a laborious and time-consuming task for expert clinicians, especially in the setting of longitudinal patient imaging. Although automated deep learning (DL) approaches can segment larger lesions effectively, they suffer from poor sensitivity of lesion detection for micro-metastases. Moreover, these approaches segment all patient imaging independently of each other, ignoring relevant information from prior time-points. In order to utilize prior time-point information, we propose SPIRS, a joint image registration and segmentation method. Given a prior time-point image and segmentation mask (which are readily available in a routine clinical environment), we affinely and deformably register these to a new time-point image. This warped prior image and mask are then used to enhance and improve the segmentation of the new time-point. We apply SPIRS to a large retrospectively acquired single institution dataset and show that it outperforms current registration approaches on BM imaging and that it significantly improves segmentation performance for micro-metastatic lesions.},
	Author = {Jay Patel and Syed Rakin Ahmed and Ken Chang and Praveer Singh and Mishka Gidwani and Katharina Hoebel and Albert Kim and Christopher Bridge and Chung-Jen Teng and Xiaomei Li and Gongwen Xu and Megan McDonald and Ayal Aizer and Wenya Linda Bi and Ina Ly and Bruce Rosen and Priscilla Brastianos and Raymond Huang and Elizabeth Gerstner and Jayashree Kalpathy-Cramer},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {565-587},
	Title = {A Deep Learning Based Framework for Joint Image Registration and Segmentation of Brain Metastases on Magnetic Resonance Imaging},
	Volume = {219},
	Year = {2023}}

@inproceedings{Pradier23,
	Abstract = {Recent advances in immunomics have shown that T-cell receptor (TCR) signatures can accurately predict active or recent infection by leveraging the high specificity of TCR binding to disease antigens. However, the extreme diversity of the adaptive immune repertoire presents challenges in reliably identifying disease-specific TCRs. Population genetics and sequencing depth can also have strong systematic effects on repertoires, which requires careful consideration when developing diagnostic models. We present an Adaptive Immune Repertoire-Invariant Variational Autoencoder (AIRIVA), a generative model that learns a low-dimensional, interpretable, and compositional representation of TCR repertoires to disentangle such systematic effects in repertoires. We apply AIRIVA to two infectious disease case-studies: COVID-19 (natural infection and vaccination) and the Herpes Simplex Virus (HSV-1 and HSV-2), and empirically show that we can disentangle the individual disease signals. We further demonstrate AIRIVA’s capability to: learn from unlabelled samples; generate in-silico TCR repertoires by intervening on the latent factors; and identify disease-associated TCRs validated using TCR annotations from external assay data.},
	Author = {Melanie F. Pradier and Niranjani Prasad and  Paidamoyo Chapfuwa and Sahra Ghalebikesabi and Maximilian Ilse and  Steven Woodhouse and Rebecca Elyanow and  Javier Zazo and Javier Gonzalez Hernandez and  Julia Greissl and Edward Meeds},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {588-611},
	Title = {AIRIVA: A Deep Generative Model of Adaptive Immune Repertoires},
	Volume = {219},
	Year = {2023}}
	
@inproceedings{Prince23,
	Abstract = {We introduce the Explainable Analytical Systems Lab (EASL) framework, an end-to-end solution designed to facilitate the development, implementation, and evaluation of clinical machine learning (ML) tools. EASL is highly versatile and applicable to a variety of contexts and includes resources for data management, ML model development, visualization and user interface development, service hosting, and usage analytics. To demonstrate its practical applications, we present the EASL framework in the context of a case study: designing and evaluating a deep learning classifier to predict diagnoses from medical imaging. The framework is composed of three modules, each with their own set of resources. The Workbench module stores data and develops initial ML models, the Canvas module contains a medical imaging viewer and web development framework, and the Studio module hosts the ML model and provides web analytics and support for conducting user studies. EASL encourages model developers to take a holistic view by integrating the model development, implementation, and evaluation into one framework, and thus ensures that models are both effective and reliable when used in a clinical setting. EASL contributes to our understanding of machine learning applied to healthcare by providing a comprehensive framework that makes it easier to develop and evaluate ML tools within a clinical setting.},
	Author = {Eric Prince  and Todd C. Hankinson and  Carsten G\"org},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {612-630},
	Title = {EASL: A Framework for Designing, Implementing, and Evaluating ML Solutions in Clinical Healthcare Settings},
	Volume = {219},
	Year = {2023}}

@inproceedings{Ramprasad23,
	Abstract = {The widespread adoption of SOAP notes for documenting diverse aspects of patient information in healthcare has been prevalent. However, the conventional process of manual note-taking is laborious and can distract healthcare providers from addressing patients’ needs. Prior work by Krishna et al. (2021a) has introduced an end-to-end pipeline for generating SOAP notes, but model-generated notes are susceptible to inaccuracies, irrelevant and missing information. In this work, we assess the performance of large language models (GPT-3.5) for SOAP note generation, compare them with fine-tuned models using automated metrics, and propose a solution to improve the consistency and faithfulness of notes by incorporating attribute-specific information via SOAP section information. To achieve this, we integrate an extra layer of unique section-specific cross-attention parameters to existing encoder-decoder architectures. Our approach is evaluated using a comprehensive suite of automated metrics and expert human evaluators, demonstrating that it leads to more accurate, relevant, and faithful information.},
	Author = {Sanjana Ramprasad and Elisa Ferracane and Sai P. Selvaraj},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {631-649},
	Title = {Generating more faithful and consistent SOAP notes using attribute-specific parameters},
	Volume = {219},
	Year = {2023}}

@inproceedings{Ranjit23,
	Abstract = {We propose Retrieval Augmented Generation (RAG) as an approach for automated radiology report writing, using multimodally-aligned embeddings from a contrastively-pretrained vision language model to retrieve relevant radiology text for a given image, and then using a general domain generative model, such as OpenAI text-davinci-003, gpt-3.5-turbo and gpt-4, to generate a report based on the retrieved text. This approach keeps hallucinated generations under check and provides capabilities to generate report content in the format we desire, leveraging the instruction following capabilities of generative models. Our approach achieves better clinical metrics with a BERTScore of 0.2865 ($\Delta$+ 25.88 %) and Semb score of 0.4026 ($\Delta$+ 6.31 %). Our approach can be useful for different clinical settings, as it can augment the automated radiology report generation process with relevant content. It also allows to inject the user intents and requirements in the prompts, which can modulate the content and format of the generated reports according to the clinical setting.},
	Author = {Mercy Ranjit and Gopinath Ganapathy and Ranjit Manuel and Tanuja Ganu},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {650-666},
	Title = {Retrieval Augmented Chest X-Ray Report Generation using OpenAI GPT models},
	Volume = {219},
	Year = {2023}}

@inproceedings{Shen23,
	Abstract = {Patients resuscitated from cardiac arrest who enter a coma are at high risk of death. Forecasting neurological outcomes of these patients (i.e., the task of neurological prognostication) could help with treatment decisions: which patients are likely to awaken from their coma and should be kept on life-sustaining therapies, and which are so ill that they would unlikely benefit from treatment? In this paper, we propose, to the best of our knowledge, the first dynamic framework for neurological prognostication of post-cardiac-arrest comatose patients using EEG data: our framework makes predictions for a patient over time as more EEG data become available, and different training patients’ available EEG time series could vary in length. Predictions themselves are phrased in terms of either time-to-event outcomes (time-to-awakening or time-to-death) or as the patient’s probability of awakening or of dying across multiple time horizons (e.g., within the next 24, 48, or 72 hours). Our framework is based on using any dynamic survival analysis model that supports competing risks in the form of estimating patient-level cumulative incidence functions. We consider three competing risks as to what happens first to a patient: awakening, being withdrawn from life-sustaining therapies (and thus deterministically dying), or dying (by other causes). For some patients, we do not know which of these happened first since they were still in a coma when data collection stopped (i.e., their outcome is censored). Competing risks models readily accommodate such patients. We demonstrate our framework by benchmarking three existing dynamic survival analysis models that support competing risks on a real dataset of 922 post-cardiac-arrest coma patients. Our main experimental findings are that: (1) the classical Fine and Gray model which only uses a patient’s static features and summary statistics from the patient’s latest hour’s worth of EEG data is highly competitive, achieving accuracy scores as high as the recently developed Dynamic-DeepHit model that uses substantially more of the patient’s EEG data; and (2) in an ablation study, we show that our choice of modeling three competing risks results in a model that is at least as accurate while learning more information than simpler models (using two competing risks or a standard survival analysis setup with no competing risks).},
	Author = {Xiaobin Shen and  Jonathan Elmer and George H. Chen},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {667-690},
	Title = {Neurological Prognostication of Post-Cardiac-Arrest Coma Patients Using EEG Data: A Dynamic Survival Analysis Framework with Competing Risks},
	Volume = {219},
	Year = {2023}}

@inproceedings{Singh23,
	Abstract = {In healthcare and biomedical applications, extreme computational requirements pose a significant barrier to adopting representation learning. Representation learning can enhance the performance of deep learning architectures by learning useful priors from limited medical data. However, state-of-the-art self-supervised techniques suffer from reduced performance when using smaller batch sizes or shorter pretraining epochs, which are more practical in clinical settings. We present Cross Architectural - Self Supervision (CASS) in response to this challenge. This novel siamese self-supervised learning approach synergistically leverages Transformer and Convolutional Neural Networks (CNN) for efficient learning. Our empirical evaluation demonstrates that CASS-trained CNNs and Transformers outperform existing self-supervised learning methods across four diverse healthcare datasets. With only 1\% labeled data for finetuning, CASS achieves a 3.8\% average improvement; with 10\% labeled data, it gains 5.9\%; and with 100\% labeled data, it reaches a remarkable 10.13\% enhancement. Notably, CASS reduces pretraining time by 69\% compared to state-of-the-art methods, making it more amenable to clinical implementation. We also demonstrate that CASS is considerably more robust to variations in batch size and pretraining epochs, making it a suitable candidate for machine learning in healthcare applications.},
	Author = {Pranav Singh and  Jacopo Cirrone},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {691-711},
	Title = {Efficient Representation Learning for Healthcare with Cross-Architectural Self-Supervision},
	Volume = {219},
	Year = {2023}}

@inproceedings{Sumer23,
	Abstract = {Deep neural networks in computer vision have shown remarkable progress in recognizing facial genetic syndromes. Many genetic syndromes are difficult to detect, even for experienced clinicians, and computer-aided phenotyping can accelerate clinical diagnosis. High-stakes clinical tasks using deep learning, as in clinical genetics, require human understandable explanations for model decisions. Saliency methods are used to explain DNN predictions in various image analysis domains but have yet to be studied in facial genetics. The syndromic features of most genetic conditions are often localized to areas like the eyes, nose, and mouth. In this paper, to summarize the contribution of key facial regions to a specific disease prediction, we propose a face region relevance score that can be applied to any saliency method. We also investigate how prior knowledge, namely human phenotype ontology and DNN model explanations, align. Quantitative experiments are performed on a new database containing over 3,500 images of 11 rare facial syndromes, a healthy control group, and an additional test set of 171 facial images, whose respective facial phenotypes are labeled by clinicians. Current saliency methods are good at capturing dysmorphism in particular regions (parts of the face), but they may not completely capture all the relevant features in a given person or condition. Our study indicates which saliency explanations and face regions are more consistent with the phenotypes of specific genetic syndromes and could be used in large-scale clinical evaluations.},
	Author = {\"Omer S\"umer and Rebekah L. Waikel and Suzanna E. Ledgister Hanchard  and Dat Duong  and  Peter Krawitz and  Cristina Conati and Benjamin D. Solomon and Elisabeth Andr\'e},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {712-736},
	Title = {Region-based Saliency Explanations on the Recognition of Facial Genetic Syndromes},
	Volume = {219},
	Year = {2023}}

@inproceedings{Vaid23,
	Abstract = {Artificial intelligence has impacted many aspects of modern medical care but depends critically on data. Videos of medical procedures are a valuable resource for computer vision algorithms but labeling them can be costly and requires expert knowledge. This paper explores how to leverage low-quality, unlabeled videos scraped from the internet in addition to a limited amount of labeled images to improve object detection during surgical procedures. We establish the first benchmark for semi-supervised hand detection during open surgery and show that existing benchmarks in non-medical contexts are not indicative of performance differences on real-world medical applications, where data is noisy and poorly labeled. We propose a end-to-end trainable two-stage object detector that employs consistency loss to learn from unlabeled images. The model is robust to missing labels, variance in hand morphology, and extreme domain shifts such as those encountered in open-source videos of surgeries scraped from YouTube. Our method can predict surgeons’ hands in surgical videos even when only a fraction of hands are labeled in each frame of the labeled set. Adding unlabeled data, we can detect hands more accurately than existing end-to-end semi-supervised object detection algorithms.},
	Author = {Pranav Vaid and Serena Yeung and Anita Rau},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {736-753},
	Title = {Robust Semi-supervised Detection of Hands in Diverse Open Surgery Environments},
	Volume = {219},
	Year = {2023}}

@inproceedings{Wadhwa23,
	Abstract = {Results from Randomized Controlled Trials (RCTs) establish the comparative effectiveness of interventions, and are in turn critical inputs for evidence-based care. However, results from RCTs are presented in (often unstructured) natural language articles describing the design, execution, and outcomes of trials; clinicians must manually extract findings pertaining to interventions and outcomes of interest from such articles. This onerous manual process has motivated work on (semi-)automating extraction of structured evidence from trial reports. In this work we propose and evaluate a text-to-text model built on instruction-tuned Large Language Models (LLMs) to jointly extract Interventions, Outcomes, and Comparators (ICO elements) from clinical abstracts, and infer the associated results reported. Manual (expert) and automated evaluations indicate that framing evidence extraction as a conditional generation task and fine-tuning LLMs for this purpose realizes considerable (∼20 point absolute F1 score) gains over the previous SOTA. We perform ablations and error analyses to assess aspects that contribute to model performance, and to highlight potential directions for further improvements. We apply our model to a collection of published RCTs through mid-2022, and release a searchable database of structured findings: http://ico-relations.ebm-nlp.com.},
	Author = {Somin Wadhwa and Jay DeYoung and  Benjamin Nye and Silvio Amir and Byron C. Wallace},	
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {754-771},
	Title = {Jointly Extracting Interventions, Outcomes, and Findings from RCT Reports with LLMs},
	Volume = {219},
	Year = {2023}}

@inproceedings{WangM23,
	Abstract = {Medical conversations between patients and medical professionals have implicit functional sections, such as “history taking”, “summarization”, “education”, and “care plan.” In this work, we are interested in learning to automatically extract these sections. A direct approach would require collecting large amounts of expert annotations for this task, which is inherently costly due to the contextual inter-and-intra variability between these sections. This paper presents an approach that tackles the problem of learning to classify medical dialogue into functional sections without requiring a large number of annotations. Our approach combines pseudo-labeling and human-in-the-loop. First, we bootstrap using weak supervision with pseudo-labeling to generate dialogue turn-level pseudo-labels and train a transformer-based model, which is then applied to individual sentences to create noisy sentence-level labels. Second, we iteratively refine sentence-level labels using a cluster-based human-in-the-loop approach. Each iteration requires only a few dozen annotator decisions. We evaluate the results on an expert-annotated dataset of 100 dialogues and find that while our models start with 69.5\% accuracy, we can iteratively improve it to 82.5\%. Code used to perform all experiments described in this paper can be found here: https://github.com/curai/curai-research/functional-sections.},
	Author = {Mengqian Wang and  Ilya Valmianski and Xavier Amatriain and Anitha Kannan},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {772-787},
	Title = {Learning functional sections in medical conversations: iterative pseudo-labeling and human-in-the-loop approach},
	Volume = {219},
	Year = {2023}}

@inproceedings{WangP23,
	Abstract = {Self-supervised representation learning on image-text data facilitates crucial medical applications, such as image classification, visual grounding, and cross-modal retrieval. One common approach involves contrasting semantically similar (positive) and dissimilar (negative) pairs of data points. Drawing negative samples uniformly from the training data set introduces false negatives, i.e., samples that are treated as dissimilar but belong to the same class. In healthcare data, the underlying class distribution is nonuniform, implying that false negatives occur at a highly variable rate. To improve the quality of learned representations, we develop a novel approach that corrects for false negatives. Our method can be viewed as a variant of debiased contrastive learning that uses estimated sample-specific class probabilities. We provide theoretical analysis of the objective function and demonstrate the proposed approach on both image and paired image-text data sets. Our experiments illustrate empirical advantages of sample-specific debiasing.},
	Author = {Peiqi Wang and Yingcheng Liu and  Ching-Yun Ko and William M. Wells and  Seth Berkowitz and  Steven Horng and  Polina Golland},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {788-803},
	Title = {Sample-Specific Debiasing for Better Image-Text Models},
	Volume = {219},
	Year = {2023}}

@inproceedings{WangY23,
	Abstract = {Large language models (LLMs) have made significant progress in various domains, including healthcare. However, the specialized nature of clinical language understanding tasks presents unique challenges and limitations that warrant further investigation. In this study, we conduct a comprehensive evaluation of state-of-the-art LLMs, namely GPT-3.5, GPT-4, and Bard, within the realm of clinical language understanding tasks. These tasks span a diverse range, including named entity recognition, relation extraction, natural language inference, semantic textual similarity, document classification, and question-answering. We also introduce a novel prompting strategy, self-questioning prompting (SQP), tailored to enhance the performance of LLMs by eliciting informative questions and answers pertinent to the clinical scenarios at hand. Our evaluation highlights the importance of employing task-specific learning strategies and prompting techniques, such as SQP, to maximize the effectiveness of LLMs in healthcare-related tasks. Our study emphasizes the need for cautious implementation of LLMs in healthcare settings, ensuring a collaborative approach with domain experts and continuous verification by human experts to achieve responsible and effective use, ultimately contributing to improved patient care. Our code is available at https://github.com/EternityYW/LLM_healthcare.},
	Author = {Yuqing Wang and Yun Zhao and  Linda Petzold},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {804-823},
	Title = {Are Large Language Models Ready for Healthcare? A Comparative Study on Clinical Language Understanding},
	Volume = {219},
	Year = {2023}}

@inproceedings{Wharrie23,
	Abstract = {Family history is considered a risk factor for many diseases because it implicitly captures shared genetic, environmental and lifestyle factors. Finland’s nationwide electronic health record (EHR) system spanning multiple generations presents new opportunities for studying a connected network of medical histories for entire families. In this work we present a graph-based deep learning approach for learning explainable, supervised representations of how each family member’s longitudinal medical history influences a patient’s disease risk. We demonstrate that this approach is beneficial for predicting 10-year disease onset for 5 complex disease phenotypes, compared to clinically-inspired and deep learning baselines for Finland’s nationwide EHR system comprising 7 million individuals with up to third-degree relatives. Through the use of graph explainability techniques, we illustrate that a graph-based approach enables more personalized modeling of family information and disease risk by identifying important relatives and features for prediction.},
	Author = {Sophie Wharrie  and Zhiyu Yang  and Andrea Ganna  and Samuel Kaski},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {824-845},
	Title = {Characterizing personalized effects of family information on disease risk using graph representation learning},
	Volume = {219},
	Year = {2023}}

@inproceedings{Wong23,
	Abstract = {Clinical trial matching is a key process in health delivery and discovery. In practice, it is plagued by overwhelming unstructured data and unscalable manual processing. In this paper, we conduct a systematic study on scaling clinical trial matching using large language models (LLMs), with oncology as the focus area. Our study is grounded in a clinical trial matching system currently in test deployment at a large U.S. health network. Initial findings are promising: out of box, cutting-edge LLMs, such as GPT-4, can already structure elaborate eligibility criteria of clinical trials and extract complex matching logic (e.g., nested AND/OR/NOT). While still far from perfect, LLMs substantially outperform prior strong baselines and may serve as a preliminary solution to help triage patient-trial candidates with humans in the loop. Our study also reveals a few significant growth areas for applying LLMs to end-to-end clinical trial matching, such as context limitation and accuracy, especially in structuring patient information from longitudinal medical records.},
	Author = {Cliff Wong and Sheng Zhang and  Yu Gu and Christine Moung and Jacob Abel and Naoto Usuyama and Roshanthi Weerasinghe  and Brian Piening and Tristan Naumann and  Carlo Bifulco  and Hoifung Poon},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {846-862},
	Title = {Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology},
	Volume = {219},
	Year = {2023}}

@inproceedings{Wu23,
	Abstract = {Deep learning models have shown great promise in various healthcare monitoring applications. However, most healthcare datasets with high-quality (gold-standard) labels are small-scale, as directly collecting ground truth is often costly and time-consuming. As a result, models developed and validated on small-scale datasets often suffer from overfitting and do not generalize well to unseen scenarios. At the same time, large amounts of imprecise (silver-standard) labeled data, annotated by approximate methods with the help of modern wearables and in the absence of ground truth validation, are starting to emerge. However, due to measurement differences, this data displays significant label distribution shifts, which motivates the use of domain adaptation. To this end, we introduce UDAMA, a method with two key components: Unsupervised Domain Adaptation and Multi-discriminator Adversarial Training, where we pre-train on the silver-standard data and employ adversarial adaptation with the gold-standard data along with two domain discriminators. In particular, we showcase the practical potential of UDAMA by applying it to Cardio-respiratory fitness (CRF) prediction. CRF is a crucial determinant of metabolic disease and mortality, and it presents labels with various levels of noise (gold- and silver-standard), making it challenging to establish an accurate prediction model. Our results show promising performance by alleviating distribution shifts in various label shift settings. Additionally, by using data from two free-living cohort studies (Fenland and BBVS), we show that UDAMA consistently outperforms up to 12\% compared to competitive transfer learning and state-of-the-art domain adaptation models, paving the way for leveraging noisy labeled data to improve fitness estimation at scale.},
	Author = {Yu Wu and Dimitris Spathis and Hong Jia and Ignacio Perez-Pozuelo and Tomas I. Gonzales and Soren Brage and  Nicholas Wareham and Cecilia Mascolo},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {863-883},
	Title = {UDAMA: Unsupervised Domain Adaptation through Multi-discriminator Adversarial Training with Noisy Labels Improves Cardio-fitness Prediction},
	Volume = {219},
	Year = {2023}}

@inproceedings{Xia23,
	Abstract = {We used survival analysis to quantify the impact of postdischarge evaluation and management (E/M) services in preventing hospital readmission or death. Our approach avoids a common pitfall when applying machine learning to this problem: inflated treatment effect estimates due to survivors bias – where the magnitude of inflation may be conditional on heterogeneous confounders in the population. This bias arises simply because in order to receive an intervention after discharge, a person must not have been readmitted in the intervening period. After deriving an expression for the phantom effect due to survivors bias, we controlled for this and other biases within an inherently interpretable model that quilts together linear functions using Bayesian multilevel modeling. We identified case management services as being the most impactful for reducing readmissions overall.},
	Author = {Hongjing Xia and Joshua C. Chang and  Sarah Nowak and Sonya Mahajan and Rohit Mahajan and Ted L. Chang and Carson C. Chow},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {884-905},
	Title = {Interpretable (not just posthoc-explainable) heterogeneous survivors bias-corrected treatment effects for assignment of postdischarge interventions to prevent readmissions},
	Volume = {219},
	Year = {2023}}

@inproceedings{Xu23,
	Abstract = {Individuals such as medical interns who work in high-stress environments often face mental health challenges including depression and anxiety. These challenges are exacerbated by the limited access to traditional mental health services due to demanding work schedules. In this context, mobile health interventions such as push notifications targeting behavioral modification to improve mental health outcomes could deliver much needed support. In this work, we study the effectiveness of these interventions on subgroups, by studying the conditional average causal effect of these interventions. We design a two step approach for estimating the conditional average causal effect of interventions and identifying specific subgroups of the population who respond positively or negatively to the interventions. The first step of our approach follows existing causal effect estimation approaches, while the second step involves a novel tree-based approach to identify subgroups who respond to the treatment. The novelty in the second step stems from a pruning approach that deploys hypothesis testing to identify subgroups experiencing a statistically significant positive or negative causal effect. Using a semi-simulated dataset, we show that our approach retrieves affected subpopulations with a higher precision than alternatives while maintaining the same recall and accuracy. Using a real dataset with randomized push interventions among the medical intern population at a large hospital, we show how our approach can be used to identify subgroups who might benefit the most from interventions.},
	Author = {Jiaai Xu and  Rada Mihalcea and Elena Frank and  Srijan Sen and Maggie Makar},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {906-922},
	Title = {Uncovering the Varied Impact of Behavioral Change Messages on Population Groups},
	Volume = {219},
	Year = {2023}}

@inproceedings{Zhang23,
	Abstract = {Real-world time-series data is riddled with heterogeneity that is often present across a number of dataset dimensions: features, labels, and time-varying factors. The heterogeneity in time-series data may be raised by introducing new features, missing data, and domain shifts in the feature dimension, and the difficulty of collecting promising ground truth results in label uncertainty. In addition, the variation on the time manner further aggravates the complexity of data heterogeneity, since the features and labels may change on the same sequence of data over time. Many machine learning techniques have been proposed to address the data heterogeneity, including transfer learning, meta-learning, semi-supervised learning, recurrent networks, etc. However, each of these techniques is limited to one type of heterogeneity. In this study, we seek to create adaptable models for the multi-source heterogeneity in time-series data. We propose a semi-supervised-based meta-learning (SSML) with an adversarial training mechanism simultaneously addressing the heterogeneous features and labeling uncertainty, a time domain variation (TDV) framework to apply SSML and transfer learning for the third level of data heterogeneity. We test our models on two medical datasets, PhysioNet Challenge 2012 and MIMIC-III ICU dataset, and improve over all benchmark models. Our code is available at https://github.com/lidazhang/ ssml-time-series-heterogeneity.git.},
	Author = {Lida Zhang and Bobak J. Mortazavi},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {923-941},
	Title = {Semi-supervised Meta-learning for Multi-source Heterogeneity in Time-series Data},
	Volume = {219},
	Year = {2023}}

@inproceedings{Zhu23,
	Abstract = {AI-driven medical history-taking is an important component in symptom checking, automated patient intake, triage, and other AI virtual care applications. As history-taking is extremely varied, machine learning models require a significant amount of data to train. To overcome this challenge, existing systems are developed using indirect data or expert knowledge. This leads to a training-inference gap as models are trained on different kinds of data than what they observe at inference time. In this work, we present a two-stage re-ranking approach that helps close the training-inference gap by re-ranking the first-stage question candidates using a dialogue-contextualized model. For this, we propose a new model, global re-ranker, which cross-encodes the dialogue with all questions simultaneously, and compare it with several existing neural baselines. We test both transformer and S4-based language model backbones. We find that relative to the expert system, the best performance is achieved by our proposed global re-ranker with a transformer backbone, resulting in a 30\% higher normalized discount cumulative gain (nDCG) and a 77\% higher mean average precision (mAP). As part of this work, we also release pre-trained checkpoints for bi-directional and autoregressive S4 models trained on Wikipedia and PubMed data.},
	Author = {Jian Zhu and Ilya Valmianski and Anitha Kannan},
	Booktitle = {Proceedings of the 8th Machine Learning for Healthcare Conference},
	Pages = {942-958},
	Title = {Dialogue-Contextualized Re-ranking for Medical History-Taking},
	Volume = {219},
	Year = {2023}}
	
